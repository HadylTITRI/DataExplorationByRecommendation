{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import certifi\n",
    "ca = certifi.where()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo as mongo\n",
    "import pandas as pd\n",
    "\n",
    "#client = mongo.MongoClient(\"mongodb+srv://hadyltitri:QScSgXpsINfxAfQC@cluster0.zvbmwjb.mongodb.net/xyzdb?retryWrites=true&w=majority\", tlsCAFile=ca)\n",
    "client = mongo.MongoClient(\"mongodb://localhost:27017/\")\n",
    "db = client[\"admin\"]\n",
    "\n",
    "collection_qst = db[\"questions_clean\"]\n",
    "collection_ans = db[\"answers_clean\"]\n",
    "\n",
    "# Identifier et supprimer les doublons basés sur l'attribut 'answer_id' dans la collection answers_clean\n",
    "duplicates = collection_ans.aggregate([\n",
    "    { '$group': { '_id': '$answer_id', 'duplicates': { '$addToSet': '$_id' }, 'count': { '$sum': 1 } } },\n",
    "    { '$match': { 'count': { '$gt': 1 } } }\n",
    "])\n",
    "\n",
    "for doc in duplicates:\n",
    "    doc['duplicates'].pop(0)  # Conserver un élément, supprimer les autres\n",
    "    collection_ans.delete_many({ '_id': { '$in': doc['duplicates'] } })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_df = list(collection_qst.find({}))\n",
    "questions_df = pd.json_normalize(questions_df)\n",
    "df_questions = pd.DataFrame(questions_df)\n",
    "\n",
    "answers_df = list(collection_ans.find({}))\n",
    "answers_df = pd.json_normalize(answers_df)\n",
    "df_answers = pd.DataFrame(answers_df)\n",
    "\n",
    "df_merged = pd.merge(df_questions,df_answers,on='question_id',how='inner')\n",
    "\n",
    "data = df_merged[['title_x','body_x', 'body_y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_x</th>\n",
       "      <th>body_x</th>\n",
       "      <th>body_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39parametercompiledvalue39 missing execution p...</td>\n",
       "      <td>question parameter sniffing execution plan att...</td>\n",
       "      <td>You can disable the parameter sniffing. When t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok index column available another index</td>\n",
       "      <td>doubt creating index table condition table 10 ...</td>\n",
       "      <td>Generally speaking having two indexes sharing ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title_x  \\\n",
       "0  39parametercompiledvalue39 missing execution p...   \n",
       "1            ok index column available another index   \n",
       "\n",
       "                                              body_x  \\\n",
       "0  question parameter sniffing execution plan att...   \n",
       "1  doubt creating index table condition table 10 ...   \n",
       "\n",
       "                                              body_y  \n",
       "0  You can disable the parameter sniffing. When t...  \n",
       "1  Generally speaking having two indexes sharing ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Vectorisation des textes\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "questions_matrix = tfidf_vectorizer.fit_transform(data['title_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extraire les noms des fonctionnalités/Le vocabumaire extraits des questions\n",
    "tfidf_tokens = tfidf_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59500, 18031)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "questions_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:993: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 980, in _score\n",
      "    scores = scorer(estimator, X_test, **score_params)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: _BaseScorer.__call__() missing 1 required positional argument: 'y_true'\n",
      "\n",
      "  warnings.warn(\n",
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1051: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Paramètres pour GridSearchCV\n",
    "param_grid = {'n_clusters': range(7, 15)}\n",
    "\n",
    "# Tester différents nombres de clusters\n",
    "# Créer un scorer pour la métrique silhouette\n",
    "silhouette_scorer = make_scorer(silhouette_score)\n",
    "\n",
    "# Recherche par grille pour le nombre de clusters avec KMeans\n",
    "kmeans = KMeans(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(kmeans, param_grid, scoring=silhouette_scorer)\n",
    "grid_search.fit(questions_matrix)\n",
    "best_num_clusters = grid_search.best_params_['n_clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_clustering = KMeans(n_clusters=best_num_clusters, random_state=42)\n",
    "question_clusters = kmeans_clustering.fit_predict(questions_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_9388\\2229855281.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['cluster'] = question_clusters\n"
     ]
    }
   ],
   "source": [
    "cluster_label = kmeans_clustering.labels_\n",
    "data['cluster'] = question_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraiter les questions\n",
    "tfidf_vectorizer1 = TfidfVectorizer(max_features=50000)  \n",
    "tfidf_matrix = tfidf_vectorizer1.fit_transform(data['title_x'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ASUS\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Créer et entraîner un modèle Keras\n",
    "input_dim = tfidf_matrix.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=input_dim, activation='relu', kernel_regularizer=l2(0.001)))#256: le nombre de neurones, input_dim : nombre de features (vecteurs) que cette couche attend en entrée\n",
    "model.add(Dropout(0.5)) # 50%=0.5 : pourcentage de neurones à supprimer ou abondonner pour réduire l'overfitting.\n",
    "model.add(Dense(128, activation='relu', kernel_regularizer=l2(0.001)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(best_num_clusters, activation='softmax'))  \n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m77s\u001b[0m 97ms/step - accuracy: 0.7810 - loss: 0.9049 - val_accuracy: 0.9779 - val_loss: 0.2479\n",
      "Epoch 2/5\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 95ms/step - accuracy: 0.9767 - loss: 0.2501 - val_accuracy: 0.9830 - val_loss: 0.2156\n",
      "Epoch 3/5\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 96ms/step - accuracy: 0.9832 - loss: 0.2202 - val_accuracy: 0.9850 - val_loss: 0.2005\n",
      "Epoch 4/5\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - accuracy: 0.9851 - loss: 0.2051 - val_accuracy: 0.9837 - val_loss: 0.1974\n",
      "Epoch 5/5\n",
      "\u001b[1m744/744\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 97ms/step - accuracy: 0.9859 - loss: 0.1949 - val_accuracy: 0.9831 - val_loss: 0.1917\n"
     ]
    }
   ],
   "source": [
    "# Entraîner le modèle\n",
    "X_train = tfidf_matrix.toarray()\n",
    "y_train = data['cluster'].values\n",
    "\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"data.pkl\", \"wb\") as f:\n",
    "    pickle.dump([questions_matrix, data, best_num_clusters, tfidf_vectorizer,tfidf_vectorizer1], f)\n",
    "\n",
    "with open(\"model.pkl\", \"wb\") as f1:\n",
    "    pickle.dump([ model, history], f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
